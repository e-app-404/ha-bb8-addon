#!/usr/bin/env python3
"""Generate per-folder index.jsonl files to seed workspace indexing.

Writes an `index.jsonl` into each directory scanned. Skips VCS, virtual envs,
and common artifact folders. Intended to be idempotent and fast.
"""
from __future__ import annotations

import hashlib
import json
import os
import re
from pathlib import Path
 

ROOT = Path(os.environ.get("REPO_ROOT", Path(__file__).resolve().parents[2]))
EXCLUDE_DIRS = {
    ".git",
    ".venv",
    "_backups",
    "_bundles",
    "htmlcov",
    "reports",
    "__pycache__",
}

# filenames that indicate CI / workflow files
CI_FILENAMES = {"dockerfile", "docker-compose.yml", "makefile"}

# package manifest names and common license files
MANIFEST_NAMES = {
    "pyproject.toml",
    "package.json",
    "requirements.txt",
    "Pipfile",
}
LICENSE_NAMES = {"license", "license.md", "copying", "copyright"}


def sha256_of_file(p: Path, max_read: int = 1024 * 1024) -> str:
    h = hashlib.sha256()
    try:
        with p.open("rb") as f:
            while True:
                chunk = f.read(8192)
                if not chunk:
                    break
                h.update(chunk)
    except Exception:
        return ""
    return h.hexdigest()


def category_guess(p: Path) -> str:
    s = str(p)
    if "/addon/" in s or s.startswith("addon/"):
        return "code.runtime"
    if "/ops/" in s or s.startswith("ops/"):
        return "code.tooling"
    if s.endswith(".md") or "/docs/" in s:
        return "docs"
    if "/tests/" in s or s.startswith("addon/tests"):
        return "tests"
    if s.startswith("reports/"):
        return "artifacts"
    if s.startswith("_backups") or s.startswith("_bundles"):
        return "artifacts.backup"
    return "other"


def sniff_file(p: Path, max_bytes: int = 4096) -> dict:
    """Return lightweight content sniff info: language, tags, generated-flag.

    Enhancements:
    - detect shebangs
    - inspect package manifests for project metadata
    - detect CI/workflow files and test files
    - detect binary files (heuristic)
    - extract license/author hints
    - extract README badges as tags
    """
    info: dict = {"language": None, "tags": [], "generated": False, "meta": {}}
    if not p.is_file():
        return info
    suffix = p.suffix.lower()
    try:
        with p.open("rb") as f:
            sample = f.read(max_bytes)
    except Exception:
        return info
    txt = b"".join(sample.splitlines(True)).decode("utf-8", errors="ignore")

    # language by extension
    if suffix in {".py"}:
        info["language"] = "python"
    elif suffix in {".sh", ".bash"}:
        info["language"] = "bash"
    elif suffix in {".yml", ".yaml"}:
        info["language"] = "yaml"
    elif suffix in {".md"}:
        info["language"] = "markdown"
    elif suffix in {".json"}:
        info["language"] = "json"
    elif suffix in {".toml"}:
        info["language"] = "toml"
    elif p.name.lower() == "dockerfile":
        info["language"] = "dockerfile"
    elif suffix in {".png", ".jpg", ".jpeg", ".gif", ".svg"}:
        # mark common image extensions as binary (no text sniffing)
        info["meta"]["binary"] = True
        return info

    # shebang
    if txt.startswith("#!"):
        firstline = txt.splitlines()[0].lower()
        if "python" in firstline:
            info["language"] = info["language"] or "python"
        elif "sh" in firstline or "bash" in firstline:
            info["language"] = info["language"] or "bash"

    # content markers -> tags and generated flag
    low = txt.lower()
    if "autogenerated" in low or "generated by" in low or "do not edit" in low:
        info["generated"] = True
        info["tags"].append("generated")
    if "pytest" in low or "import pytest" in low:
        info["tags"].append("pytest")
    if "homeassistant" in low or "ha_discovery" in low or "discovery" in low:
        info["tags"].append("homeassistant")
    if "mqtt" in low:
        info["tags"].append("mqtt")
    if "ble" in low or "bluetooth" in low:
        info["tags"].append("ble")
    if "coverage" in low or "fail_under" in low:
        info["tags"].append("coverage")
    if "copyright" in low or "license" in low:
        info["tags"].append("license")
    # README badges often include technology names
    if "badge" in low and "travis" not in low:
        # simple heuristic to pick out common badge keywords
        for kw in (
            "python",
            "pytest",
            "coverage",
            "docker",
            "homeassistant",
            "mqtt",
        ):
            if kw in low:
                info["tags"].append(kw)

    # detect typical CI/workflow files
    if (
        p.name.lower() in CI_FILENAMES
        or str(p).lower().startswith(".github/workflows")
    ):
        info["tags"].append("ci")

    # detect package manifests and extract simple metadata
    if p.name in MANIFEST_NAMES:
        info["tags"].append("manifest")
        # try to extract a top-level name or author
        if "name" in low:
            m = re.search(
                r"name\s*[:=]\s*[\'\"]?([\w\-\.]+)[\'\"]?",
                txt,
                re.I,
            )
            if m:
                info["meta"]["project_name"] = m.group(1)
        if "author" in low:
            m = re.search(
                r"author\s*[:=]\s*[\'\"]?([^\n\'\"]+)[\'\"]?",
                txt,
                re.I,
            )
            if m:
                info["meta"]["author"] = m.group(1).strip()

    # license file heuristics
    if p.name.lower() in LICENSE_NAMES:
        info["tags"].append("license")
        info["meta"]["license_file"] = True

    # filename heuristics
    name = p.name.lower()
    if name.startswith("test_") or name.endswith("_test.py"):
        info["tags"].append("test")
    if name.endswith(".md"):
        info["tags"].append("doc")
    if any(name == n for n in MANIFEST_NAMES):
        info["tags"].append("manifest")
    if (
        name in CI_FILENAMES
        or (name.endswith(".yml") and ".github" in str(p).lower())
    ):
        info["tags"].append("ci")

    # dedupe tags
    info["tags"] = sorted(set(info["tags"]))
    return info


def make_entry(root: Path, path: Path) -> dict:
    rel = path.relative_to(root).as_posix()
    try:
        stat = path.stat()
        size = stat.st_size
    except Exception:
        size = 0
    sniff = sniff_file(path)
    entry = {
        "path": rel,
        "name": path.name,
        "size": size,
        "sha256": sha256_of_file(path) if path.is_file() else "",
        "category": category_guess(path),
        "language": sniff.get("language"),
        "tags": sniff.get("tags", []),
        "generated": bool(sniff.get("generated", False)),
    }
    return entry


def write_index_for_dir(d: Path) -> None:
    entries = []
    for child in sorted(d.iterdir()):
        if child.name in EXCLUDE_DIRS:
            continue
        if child.name == "index.jsonl":
            continue
        entries.append(make_entry(d, child))
    if not entries:
        return
    out = d / "index.jsonl"
    with out.open("w", encoding="utf-8") as f:
        for e in entries:
            f.write(json.dumps(e, ensure_ascii=False) + "\n")


def walk_and_index(root: Path) -> None:
    for d, _dirs, _files in os.walk(root):
        p = Path(d)
        parts = set(p.parts)
        if parts & EXCLUDE_DIRS:
            # skip directories that intersect excluded names
            continue
        # Write index for this directory
        write_index_for_dir(p)


if __name__ == "__main__":
    walk_and_index(ROOT)
